{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "token = \"Your Quandl token\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name, link, startDate, endDate):\n",
    "    q_data = quandl.get(link, start_date=startDate, end_date=endDate, authtoken= token)\n",
    "    df = pd.DataFrame(index=range(2001,2015))\n",
    "    for i in pd.unique(q_data.index.year):\n",
    "        df.loc[i, name] = q_data.VALUE[str(i)][-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data2(name, link, startDate, endDate):\n",
    "    q_data = quandl.get(link, start_date=startDate, end_date=endDate, authtoken= token)\n",
    "    df = pd.DataFrame(index=range(2001,2015))\n",
    "    for i in pd.unique(q_data.index.year):\n",
    "        df.loc[i, name] = q_data['Adjusted Close'][str(i)][-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_data = get_data(\"GDP\", \"FRED/GDP\", \"2001-12-31\", \"2015-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = \"2001-01-01\"\n",
    "finsh_date = \"2015-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GDPq   = get_data(\"GDP\"   , \"FRED/GDP\", start_date, finsh_date) # Gross Domestic Product\n",
    "CPIq   = get_data(\"CPI\"   , \"FRED/CPIAUCSL\", start_date, finsh_date) # Consumer Price Index \n",
    "M1q    = get_data(\"M1\"    , \"FRED/M1\" , start_date, finsh_date) # M1\n",
    "M2q    = get_data(\"M2\"    , \"FRED/M2\" , start_date, finsh_date) # M2\n",
    "DFFq   = get_data(\"DFF\"   , \"FRED/DFF\", start_date, finsh_date) # Effective Federal Funds Rate\n",
    "DGS30q = get_data(\"DGS30\" , \"FRED/DGS30\", start_date, finsh_date) # 30-Year Treasury Constant Maturity Rate\n",
    "UNRATEq= get_data(\"UNRATE\", \"FRED/UNRATE\", start_date, finsh_date) # Civilian Unemployment Rate\n",
    "TOBq   = get_data(\"TOB\"   , \"FRED/BOPGSTB\", start_date, finsh_date) # Trade Balance: Goods and Services, Balance of Payments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Macro Economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([GDPq, CPIq, M1q, M2q, DFFq, DGS30q, UNRATEq, TOBq], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exchange rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USD_EURq   = get_data(\"USD_EUR\"   , \"FRED/DEXUSEU\", start_date, finsh_date) # U.S. Dollars to One Euro\n",
    "USD_BPSq   = get_data(\"USD_BPS\"   , \"FRED/AEXUSUK\", start_date, finsh_date) # U.S. Dollars to One British Pound\n",
    "USD_AUDq   = get_data(\"USD_AUD\"   , \"FRED/AEXUSAL\", start_date, finsh_date) # U.S. Dollars to One Australian Dollar\n",
    "USD_JPYq   = get_data(\"USD_JPY\"   , \"FRED/AEXJPUS\", start_date, finsh_date) # Japanese Yen to One U.S. Dollar \n",
    "USD_CHYq   = get_data(\"USD_CHY\"   , \"FRED/AEXCHUS\", start_date, finsh_date) # Chinese Yuan to One U.S. Dollar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([USD_EURq, USD_BPSq, USD_AUDq, USD_JPYq, USD_CHYq ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAPq   = get_data2(\"SAP\"   , \"YAHOO/INDEX_GSPC\", start_date, finsh_date) # S&P 500 Index\n",
    "NIFTIq = get_data2(\"NIFTY\" , \"YAHOO/INDEX_NSEI\", start_date, finsh_date) # Nifty Index\n",
    "SSEq   = get_data2(\"SSE\"   , \"YAHOO/SS_000001\" , start_date, finsh_date) # SSE Composite Index - Shanghai Stock Exchange\n",
    "FTSEq  = get_data2(\"FTSE\"  , \"BCIW/_FTSE\", start_date, finsh_date) # FTSE 100 Index Portfolio Class I\n",
    "NIKKEIq= get_data2(\"NIKKEI\", \"YAHOO/INDEX_N225\", start_date, finsh_date) # Nikkei 225 Index (Japan)\n",
    "TWIq   = get_data2(\"TWI\"   , \"YAHOO/INDEX_TWII\", start_date, finsh_date) # Taiwan Weighted Index\n",
    "ASXq   = get_data2(\"ASX\"   , \"YAHOO/INDEX_AXJO\", start_date, finsh_date) # S&P/ASX 200 Index (Australia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([SAPq, NIFTIq, SSEq, FTSEq, NIKKEIq, TWIq, ASXq], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data3(name, link, startDate, endDate):\n",
    "    q_data = Quandl.get(link+'.6', start_date=startDate, end_date=endDate, authtoken= token)\n",
    "    df = pd.DataFrame(index=range(2001,2015))\n",
    "    for i in pd.unique(q_data.index.year):\n",
    "        df.loc[i, name] = q_data[q_data.index.year == int(i)].mean()[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data4(name, link, startDate, endDate):\n",
    "    q_data = Quandl.get(link+'.4', start_date=startDate, end_date=endDate, authtoken= token)\n",
    "    df = pd.DataFrame(index=range(2001,2015))\n",
    "    for i in pd.unique(q_data.index.year):\n",
    "        df.loc[i, name] = q_data[q_data.index.year == int(i)].mean()[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(ticker, startDate, endDate):\n",
    "    df = quandl.get('YAHOO/'+ticker, start_date=startDate, end_date=endDate, authtoken= token)\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df['Ticker'] = ticker\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_price2(ticker, startDate, endDate):\n",
    "    df = web.DataReader(ticker, 'yahoo', startDate, endDate)\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df['Ticker'] = ticker\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def day_stock_price(df, ticker, req_date):\n",
    "    return float(df[(df.Date == req_date) & (df.Ticker == ticker)]['Adj Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_pickle(file, file_path, file_name):\n",
    "    '''\n",
    "    pickle file\n",
    "    file is the target file to pickle\n",
    "    file_path is the folder location\n",
    "    file_name is the name we want to save the target file\n",
    "    no need for .pkl\n",
    "    '''\n",
    "    full_path = str(file_path) + str(file_name) + '.pkl'\n",
    "    pickle.dump(file, open(full_path, 'wb'))\n",
    "\n",
    "\n",
    "def from_pickle(file_path):\n",
    "    '''\n",
    "    load pickle file\n",
    "    file path is the full path and name of the file plus .pkl\n",
    "    '''\n",
    "    return pickle.load(open(file_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract daily stock price from WIKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ticker_lst3 = ['VFIAX','VTSAX','VINIX','VTSMX','VIIIX','VGTSX','FCNTX','AMECX','AGTHX']\n",
    "ticker_lst4 = ['AAPL','T','JNJ','INDEX_SPY','FUND_VFIAX','FUND_VTSAX','FUND_VTSMX']\n",
    "ticker_lst5 = ['JNJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "startDate = \"2001-01-01\"\n",
    "endDate   = \"2016-12-31\"\n",
    "df_price  = pd.DataFrame() \n",
    "missing   = []\n",
    "\n",
    "for tic in ticker_lst5:\n",
    "    try:\n",
    "        df_i = quandl.get('YAHOO/'+tic, start_date=startDate, end_date=endDate, authtoken= token)\n",
    "        df_i['Date'] = df_i.index\n",
    "        df_i['Ticker'] = tic\n",
    "        df_price = df_price.append(df_i,ignore_index=True)\n",
    "        del df_i\n",
    "    except:\n",
    "        missing.append(tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open                           118.44\n",
       "High                           118.44\n",
       "Low                            118.44\n",
       "Close                          118.44\n",
       "Volume                              0\n",
       "Adjusted Close                88.3557\n",
       "Date              2001-01-02 00:00:00\n",
       "Ticker                          VFIAX\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price['Year'] = df_price['Date'].apply(lambda x: str(x.year))\n",
    "df_price['Month'] = df_price['Date'].apply(lambda x: str(x.month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_price['Year'] = df_price['Date'].apply(lambda x: str(x[:4]))\n",
    "df_price['Month'] = df_price['Date'].apply(lambda x: str(x[5:7]))\n",
    "del df_price['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average stock price \n",
    "df_ave_price = pd.DataFrame()\n",
    "\n",
    "for tic in ticker_lst4:\n",
    "    df_i = df_price[(df_price.Ticker == tic)].groupby('Year')['Adjusted Close'].mean().to_frame().reset_index()\n",
    "    df_i['Ticker'] = tic\n",
    "    df_ave_price = df_ave_price.append(df_i,ignore_index=True)\n",
    "    del df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['yr_ave_return'] = ''\n",
    "for i in range(len(df0)):\n",
    "    try:\n",
    "        tic = df0.loc[i,'Ticker']\n",
    "        yr  = df0.loc[i,'Year']\n",
    "        df0.loc[i,'yr_ave_return'] =float(df_ave_price[(df_ave_price.Ticker == tic) & (df_ave_price.Year == yr)]['yr_ave_return'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df0[df0.Ticker == 'AAPL']['y_ave_price']\n",
    "ix = df_i.index.tolist()\n",
    "for j in ix:\n",
    "    try:\n",
    "        y_return =  (df_i[j+1] - df_i[j]) / df_i[j]\n",
    "    else:\n",
    "        y_return = nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_return_lst = []\n",
    "\n",
    "for tic in ticker_lst3:\n",
    "    df_i = df_ave_price[df_ave_price.Ticker == tic]['Adjusted Close']\n",
    "    ix = df_i.index.tolist()\n",
    "    for j in ix:\n",
    "        try:\n",
    "            y_return = (df_i[j+1]-df_i[j])/df_i[j]\n",
    "        except:\n",
    "            y_return = np.nan\n",
    "        y_return_lst.append(y_return)\n",
    "df_ave_price['yr_ave_return'] = y_return_lst"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
